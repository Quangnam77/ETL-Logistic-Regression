# -*- coding: utf-8 -*-
"""ETL & Logistic Regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KKIQHymW9KTj4ZTdFBIcbuqs3xMseCBb

Add libraries needed
"""

import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

"""Extract data from every sources"""

#Enrollies
google_sheet_id = '1VCkHwBjJGRJ21asd9pxW4_0z2PWuKhbLR3gUHm-p4GI'
url = 'https://docs.google.com/spreadsheets/d/' + google_sheet_id + "/export?format=xlsx"
enrollies = pd.read_excel(url, sheet_name ='enrollies')

"""Transform data"""

enrollies.info()
enrollies.describe()
enrollies.head(5)

"""1/ Change type"""

#Change type
cols_name = ['city', 'gender']
enrollies['full_name'] = enrollies['full_name'].astype('string')
enrollies[cols_name] = enrollies[cols_name].astype('category')
enrollies.info()

#Add unknow to gender column
enrollies['gender']= enrollies['gender'].cat.add_categories('unknown')
#fill missing value
enrollies['gender']=enrollies['gender'].fillna('unknown').astype('category')
enrollies.info()

enrollies.head(5)

#standardize value
cat_cols = ['full_name','city', 'gender']
for col in cat_cols:
    enrollies[col] = enrollies[col].str.lower()
enrollies.head(5)

"""Enrollies' education

Extract data
"""

enrollies_edu= pd.read_excel('enrollies_education.xlsx')

"""Check data about info, describe, head"""

enrollies_edu.info()
enrollies_edu.describe()
enrollies_edu.head(5)

"""ETL data"""

#Change type
cols_edu= ['enrolled_university', 'education_level', 'major_discipline']
enrollies_edu[cols_edu] = enrollies_edu[cols_edu].astype('category')
enrollies_edu.info()

#Fill na
cols_edu= ['enrolled_university', 'education_level', 'major_discipline']
for col in cols_edu:
    enrollies_edu[col] = enrollies_edu[col].cat.add_categories('unknown')
    enrollies_edu[col] = enrollies_edu[col].fillna('unknown').astype('category') # Apply fillna to each column

enrollies_edu.info()

#standarlize data
cat_cols = ['enrolled_university','education_level', 'major_discipline']
for col in cat_cols:
    enrollies_edu[col] = enrollies_edu[col].str.upper()
enrollies_edu.head(5)

"""Enrollies' working experience"""

#Extract data
enrollies_workex= pd.read_csv('work_experience.csv')

enrollies_workex.info()
enrollies_workex.describe()
enrollies_workex.head(5)

"""ETL data"""

enrollies_workex['experience'].unique()

enrollies_workex['last_new_job'].unique()

#Change type
workex_cols= ['relevent_experience','company_size','company_type']
enrollies_workex[workex_cols] = enrollies_workex[workex_cols].astype('category')
enrollies_workex['experience'] = enrollies_workex['experience'].astype('string')
enrollies_workex['last_new_job'] = enrollies_workex['last_new_job'].astype('string')
enrollies_workex.info()

#Fill Na
col_cats1=['company_size','company_type']
col_cats2=['experience','last_new_job']
for col in col_cats1:
    enrollies_workex[col] = enrollies_workex[col].cat.add_categories('unknown')
    enrollies_workex[col] = enrollies_workex[col].fillna('unknown').astype('category')
enrollies_workex = enrollies_workex.dropna(subset=['experience', 'last_new_job'])
enrollies_workex.info()

#Standarlize data
cat_cols3 = ['relevent_experience','company_type']
for col in cat_cols3:
    enrollies_workex[col] = enrollies_workex[col].str.capitalize()
enrollies_workex.head(5)

"""Training hours (LMS)"""

!pip install pymysql

from sqlalchemy import create_engine
import pymysql
engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')
training_hours = pd.read_sql_table('training_hours', engine)

"""Check dataframe"""

training_hours.info()
training_hours.describe()
training_hours.head(5)

"""5. City development index"""

tables = pd.read_html('https://sca-programming-school.github.io/city_development_index/index.html')
cities_dev = tables[0]
cities_dev.head(5)

"""6/Employment"""

from sqlalchemy import create_engine
import pymysql
table = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')
employment = pd.read_sql_table('employment', table)

employment.info()
employment.describe()
employment.head(5)

"""## Load data"""

#refactoring
db_path='data_warehouse.db'
engine = create_engine(f'sqlite:///{db_path}')
tables = {
    "enrollies": enrollies,
    "enrollies_edu": enrollies_edu,
    "enrollies_workex": enrollies_workex,
    "training_hours": training_hours,
    "cities_dev": cities_dev,
    "employment": employment
}

for name, df in tables.items():
    df.to_sql(name, engine, if_exists="replace", index=False)